# coding=utf-8
# [model]
# str: "abc", not 'abc', 
# don't use \"
# extend: a:b:c means a extend from b，c. 
# 支持单线继承，未支持递归继承。即，a继承b，接着继承c。
# 注意：此处继承只针对参数配置文件，不代表模型本身。

[seq2seqv2nn]
{
    "dataset" : "res",
    "nepoch" : 150,
    "batch_size" : 64,
    "test_batch_size" : 64,
    "init_lr" : 0.001,
    "stddev" : 0.05,
    "emb_stddev" : 0.002,
    "edim" : 300,
    "max_grad_norm" : 150,  # if set None, while not clip the grads.
    "pad_idx" : 0,
    "emb_up" : false,  # should update the pre-train embedding.
    "update_lr" : false,
    "multi_layer" : null, # int or None
    "decay_steps" : 1,
    "decay_rate" : 0.1,
    "active" : "tanh",
    # is reversing the input
    "reverse" : false,
    # is multi_layer use the same lstm cell
    "same_cell" : true,
    # lstm
    "hidden_size" : 300,
    "output_keep_probs" : 0.8,
    "cell" : "lstm", # "gru", lstm"
    "eos" : true,
    "e_time_step" : 7,
    "o_time_step" : 7,
    "model_save_path" : "/home/herb/code/WWW18/ckpt/",
    "lap_threshold_acc" : 0.75,
	"res_threshold_acc" : 0.808,
	"dong_threshold_acc" : 0.699
}

[mlpattv1_tri_single : seq2seqv2nn]
{
    "nepoch" : 70,
	"batch_size":1,
    "init_lr" : 0.001,
	"print_all":true,
	"norm_type" : "softmax",
	"emb_up": false,
    "eos" : false,
    "cell" : "gru",
    "time_step" : 7,
    "is_add" : true,
    "w_shapes" :[[300,300]],
    "attlayer" : "fwnn3",
    "is_concat_asp": false,
    "use_gate": false,
    "is_share_att" : true,
    "is_add_onetime": false
}
